# -*- coding: utf-8 -*-
"""compute-qid-types.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CKpcehEAeFdoPqn1w7AQiZD8coNikz2q
"""

import json
import pickle
import random
import re
import time
import requests
import sys
from collections import Counter


class CLOCQInterfaceClient:
    def __init__(self, host="http://localhost", port="7777"):
        self.host = host
        self.port = port
        self.req = requests.Session()
        self.ENTITY_PATTERN = re.compile("^Q[0-9]+$")
        self.PRED_PATTERN = re.compile("^P[0-9]+$")

    def get_label(self, kb_item):
        """
        Retrieves a single label for the given KB item.
        E.g. "France national association football team" for "Q47774".

        Note: The n-triples Wikidata dump stores multiple labels (not aliases) for the same item.
        Here, we return the first KB label which is not exactly the KB item id (i.e. "Q47774").
        Shown as "Label" in Wikidata.
        """
        params = {"item": kb_item}
        res = self._req("/item_to_label", params)
        json_string = res.content.decode("utf-8")
        label = json.loads(json_string)
        return label

    def get_labels(self, kb_item):
        """
        Retrieves the list of label for the given KB item.
        E.g. ["France national association football team", "France national team"] for "Q47774".

        Note: The n-triples Wikidata dump stores multiple labels (not aliases) for the same item.
        Here, we return the full list of KB labels stored in the n-triples dump.
        Shown as "Label" in Wikidata.
        """
        params = {"item": kb_item}
        res = self._req("/item_to_labels", params)
        json_string = res.content.decode("utf-8")
        label = json.loads(json_string)
        return label

    def get_aliases(self, kb_item):
        """
        Retrieves the aliases for the given KB item.
        E.g. "France" for "Q47774".
        Shown as "Also known as" in Wikidata.
        """
        params = {"item": kb_item}
        res = self._req("/item_to_aliases", params)
        json_string = res.content.decode("utf-8")
        aliases = json.loads(json_string)
        return aliases

    def get_description(self, kb_item):
        """
        Retrieves the description for the given KB item.
        The descriptions can be seen on top of Wikidata pages.
        E.g. "men's national association football team representing France" for "Q47774".
        Shown as "Description" in Wikidata.
        """
        params = {"item": kb_item}
        res = self._req("/item_to_description", params)
        json_string = res.content.decode("utf-8")
        aliases = json.loads(json_string)
        return aliases

    def get_types(self, kb_item):
        """
        Retrieves the types for the given KB item.
        Returns list of items with keys: {"id", "label"}.
        E.g. {"id": "Q6979593", "label": "national association football team"} for "Q47774".
        """
        params = {"item": kb_item}
        res = self._req("/item_to_types", params)
        json_string = res.content.decode("utf-8")
        types = json.loads(json_string)
        return types

    def get_frequency(self, kb_item):
        """
        A list of two frequency numbers for the given KB item:
        - number of facts with the item occuring as subject
        - number of facts with the item occuring as object/qualifier-object.
        """
        params = {"item": kb_item}
        res = self._req("/frequency", params)
        json_string = res.content.decode("utf-8")
        frequencies = json.loads(json_string)
        return frequencies

    def get_neighborhood(self, kb_item, p=1000, include_labels=True):
        """
        Returns a list of facts including the item (the 1-hop neighborhood)
        each fact is a n-tuple, with subject, predicate, object and qualifier information.
        """
        params = {"item": kb_item, "p": p, "include_labels": include_labels}
        res = self._req("/neighborhood", params)
        json_string = res.content.decode("utf-8")
        neighbors = json.loads(json_string)
        return neighbors

    def get_neighborhood_two_hop(self, kb_item, p=1000, include_labels=True):
        """
        Returns a list of facts in the 2-hop neighborhood of the item
        each fact is a n-tuple, with subject, predicate, object and qualifier information.
        """
        params = {"item": kb_item, "p": p, "include_labels": include_labels}
        res = self._req("/two_hop_neighborhood", params)
        json_string = res.content.decode("utf-8")
        neighbors = json.loads(json_string)
        return neighbors

    def connect(self, kb_item1, kb_item2):
        """
        Returns a list of paths between item1 and item2. Each path is given by either 1 fact
        (1-hop connection) or 2 facts (2-hop connections).
        """
        params = {"item1": kb_item1, "item2": kb_item2}
        res = self._req("/connect", params)
        json_string = res.content.decode("utf-8")
        paths = json.loads(json_string)
        return paths

    def connectivity_check(self, kb_item1, kb_item2):
        """
        Returns the distance of the two items in the graph, given a fact-based definition.
        Returns 1 if the items are within 1 hop of each other,
        Returns 0.5 if the items are within 2 hops of each other,
        and returns 0 otherwise.
        """
        params = {"item1": kb_item1, "item2": kb_item2}
        res = self._req("/connectivity_check", params)
        connectivity = float(res.content)
        return connectivity

    def get_search_space(self, question, parameters=dict(), include_labels=True):
        """
        Extract a question-specific context for the given question using the CLOCQ algorithm.
        Returns k (context tuple, context graph)-pairs for the given questions,
        i.e. a mapping of question words to KB items and a question-relevant KG subset.
        In case the dict is empty, the default CLOCQ parameters are used
        """
        params = {"question": question, "parameters": parameters, "include_labels": include_labels}
        res = self._req("/search_space", params)
        json_string = res.content.decode("utf-8")
        result = json.loads(json_string)
        return result

    def is_wikidata_entity(self, string):
        """
        Check whether the given string can be a wikidata entity.
        """
        return self.ENTITY_PATTERN.match(string) is not None

    def is_wikidata_predicate(self, string):
        """
        Check whether the given string can be a wikidata predicate.
        """
        return self.PRED_PATTERN.match(string) is not None

    def _req(self, action, json):
        if self.port == "443":
            return self.req.post(self.host + action, json=json)
        else:
            return self.req.post(self.host + ":" + self.port + action, json=json)

def normalize_labels(types):
    #print(types)
    try:
        types.remove({'id': 'Q5', 'label': 'human'})
    except:
        pass
    for t in types:
        t["label"] = t["label"].replace(" ","_").lower()


def compute_global_distribution(results):
    distribution = Counter()
    for r in results:
        for t in r["types"]:
            distribution[t["label"]] += 1
    return distribution

def get_max_label(types, type_distribution):
    most_frequent_type = None
    highest_frequency = 0

    for t in types:
        t_label = t["label"]
        t_freq = type_distribution[t_label]
        if t_freq > highest_frequency:
            highest_frequency = t_freq
            most_frequent_type = t_label
    return most_frequent_type



def main():
    """
    Invoke this module as a script
    """
    import argparse

    argparse.ArgumentParser(description='Process some integers.')
    parser = argparse.ArgumentParser(
        usage = '%(prog)s [OPTIONS] [ARGS...]',
        description='Calculate something',
        epilog='Contact simon.clematide@uzh.ch'
        )
    parser.add_argument('--version', action='version', version='0.99')
    parser.add_argument('-l', '--logfile', dest='logfilename',
                      help='write log to FILE', metavar='FILE')
    parser.add_argument('-q', '--quiet',
                      action='store_true', dest='quiet', default=False,
                      help='do not print status messages to stderr')
    parser.add_argument('-d', '--debug',
                      action='store_true', dest='debug', default=False,
                      help='print debug information')
    parser.add_argument('input')
    args = parser.parse_args()


    cloq = CLOCQInterfaceClient(host="https://clocq.mpi-inf.mpg.de/api/",port="443")

    most_frequent_label_distro = Counter()
    results = []
    item = 0
    with open(args.input) as f:
        for l in f:
            item += 1
            freq,qid = l.strip().split()
            types = cloq.get_types(qid)
            normalize_labels(types)

            results.append({"freq":int(freq),"qid":qid,"types":types})
            if item > 100000:
                break
        distribution = compute_global_distribution(results)

        for r in results:
            most_freq_label = get_max_label(r["types"],distribution)
            r["most_freq_label"] = most_freq_label
            most_frequent_label_distro[most_freq_label] += 1
        print(most_frequent_label_distro,file=sys.stderr)


# {'freq': 21, 'qid': 'Q295090', 'types': [{'id': 'Q82955', 'label': 'politician'}, {'id': 'Q40348', 'label': 'lawyer'}], 'most_freq_label': 'politician'}
        for r in results:
            print(r["qid"],r["most_freq_label"],sep="\t")

if __name__ == '__main__':
    main()





